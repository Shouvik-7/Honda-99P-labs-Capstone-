{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPWEM1acpsMqm5WDbc0vgUm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Problem Statement:\n","\n","Given the provided dataset containing telematics data from over 50,000 anonymized driver trips, the objective is to leverage this data to develop useful applications in the automobile domain. Specifically, we aim to explore potential use cases such as driver recommendations for trips and driver profiling based on their behavior.\n","\n","Objective:\n","\n","1. Driver Recommendations for Trips: Develop an algorithm that can recommend suitable drivers for specific types of trips based on their driving behavior and preferences as well (if customer-specific or some other context that we think of using  can be obtained then more of a contextual bandit can be prepared,  multiple algos can be fit into the framework letting the framework pick the best model)\n","\n","2. Driver Profiling: Create profiles for individual drivers based on their driving patterns, habits, and risk factors to better understand their driving style and preferences.\n"],"metadata":{"id":"zu6_G9uXMqie"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9EDOBpl4MiB4","executionInfo":{"status":"ok","timestamp":1713651808105,"user_tz":360,"elapsed":16406,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}},"outputId":"91c0ebed-557a-4ea5-9356-60434376f8c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","source":["# Importing packages\n","\n","import pandas as pd\n","import numpy as np\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","pd.set_option('display.max_rows', None)\n","pd.set_option('display.max_columns', None)\n","\n","from sklearn.ensemble import IsolationForest\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"EnQvDMqVMxf0","executionInfo":{"status":"ok","timestamp":1713651815210,"user_tz":360,"elapsed":2306,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Reading cleaned hvcan data from csv file\n","\n","hvcan = pd.read_csv('/content/drive/MyDrive/Honda Capstone Project- MOVE/cleaned_hvcan.csv')\n","\n","hvcan.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"id":"daRcMTqxM13M","executionInfo":{"status":"ok","timestamp":1713651823047,"user_tz":360,"elapsed":7019,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}},"outputId":"27b9eecd-adb1-43b9-ae13-90683a241504"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0 partitionDate  device  filedate  filetimeutc  engineTorque  \\\n","0           0    2022-01-01    3077  20220101       130718        6553.4   \n","1           1    2022-01-01    3077  20220101       130718        6553.4   \n","2           2    2022-01-01    3077  20220101       130718        6553.4   \n","3           3    2022-01-01    3077  20220101       130718        6553.4   \n","4           4    2022-01-01    3077  20220101       130718        6553.4   \n","\n","   engineCoolantTemp  engineAtmosphericPressure  steeringSpeed  engineSpeed  \\\n","0                -41                       91.4              0            0   \n","1                -41                       91.4              0            0   \n","2                -41                       91.4              0            0   \n","3                -41                       91.4              0            0   \n","4                -41                       91.4              0            0   \n","\n","   steeringTorque  epsLoad  accLsfSubseg  fuelUsed  cabinTemp  compCurrent  \\\n","0             0.0      0.0             0       0.0          0            0   \n","1             0.0      0.0             0       0.0          0            0   \n","2             0.0      0.0             0       0.0          0            0   \n","3             0.0      0.0             0       0.0          0            0   \n","4             0.0      0.0             0       0.0          0            0   \n","\n","   latAccel  accelPedalPos  wheelVelLF  wheelVelRF  wheelVelLR  wheelVelRR  \\\n","0       0.0              0         0.0         0.0         0.0         0.0   \n","1       0.0              0         0.0         0.0         0.0         0.0   \n","2       0.0              0         0.0         0.0         0.0         0.0   \n","3       0.0              0         0.0         0.0         0.0         0.0   \n","4       0.0              0         0.0         0.0         0.0         0.0   \n","\n","   accStatus  odometerMiles  driverSeatbelt  accSetSpeed  cruiseSetSpeed  \\\n","0          0            0.0           False          0.0             0.0   \n","1          0            0.0           False          0.0             0.0   \n","2          0            0.0           False          0.0             0.0   \n","3          0            0.0           False          0.0             0.0   \n","4          0            0.0           False          0.0             0.0   \n","\n","   tirePressureLF  tirePressureRF  tirePressureLR  tirePressureRR  \\\n","0               0               0               0               0   \n","1               0               0               0               0   \n","2               0               0               0               0   \n","3               0               0               0               0   \n","4               0               0               0               0   \n","\n","   outsideAirTemp  tmDisplayedGear  absWheelSpeedFL  absWheelSpeedFR  \\\n","0             0.0                0              0.0              0.0   \n","1             0.0                0              0.0              0.0   \n","2             0.0                0              0.0              0.0   \n","3             0.0                0              0.0              0.0   \n","4             0.0                0              0.0              0.0   \n","\n","   absWheelSpeedRL  absWheelSpeedRR  \n","0              0.0              0.0  \n","1              0.0              0.0  \n","2              0.0              0.0  \n","3              0.0              0.0  \n","4              0.0              0.0  "],"text/html":["\n","  <div id=\"df-579d8cb7-9c8a-43da-9298-d2ea0e1c7b76\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>partitionDate</th>\n","      <th>device</th>\n","      <th>filedate</th>\n","      <th>filetimeutc</th>\n","      <th>engineTorque</th>\n","      <th>engineCoolantTemp</th>\n","      <th>engineAtmosphericPressure</th>\n","      <th>steeringSpeed</th>\n","      <th>engineSpeed</th>\n","      <th>steeringTorque</th>\n","      <th>epsLoad</th>\n","      <th>accLsfSubseg</th>\n","      <th>fuelUsed</th>\n","      <th>cabinTemp</th>\n","      <th>compCurrent</th>\n","      <th>latAccel</th>\n","      <th>accelPedalPos</th>\n","      <th>wheelVelLF</th>\n","      <th>wheelVelRF</th>\n","      <th>wheelVelLR</th>\n","      <th>wheelVelRR</th>\n","      <th>accStatus</th>\n","      <th>odometerMiles</th>\n","      <th>driverSeatbelt</th>\n","      <th>accSetSpeed</th>\n","      <th>cruiseSetSpeed</th>\n","      <th>tirePressureLF</th>\n","      <th>tirePressureRF</th>\n","      <th>tirePressureLR</th>\n","      <th>tirePressureRR</th>\n","      <th>outsideAirTemp</th>\n","      <th>tmDisplayedGear</th>\n","      <th>absWheelSpeedFL</th>\n","      <th>absWheelSpeedFR</th>\n","      <th>absWheelSpeedRL</th>\n","      <th>absWheelSpeedRR</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2022-01-01</td>\n","      <td>3077</td>\n","      <td>20220101</td>\n","      <td>130718</td>\n","      <td>6553.4</td>\n","      <td>-41</td>\n","      <td>91.4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2022-01-01</td>\n","      <td>3077</td>\n","      <td>20220101</td>\n","      <td>130718</td>\n","      <td>6553.4</td>\n","      <td>-41</td>\n","      <td>91.4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2022-01-01</td>\n","      <td>3077</td>\n","      <td>20220101</td>\n","      <td>130718</td>\n","      <td>6553.4</td>\n","      <td>-41</td>\n","      <td>91.4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2022-01-01</td>\n","      <td>3077</td>\n","      <td>20220101</td>\n","      <td>130718</td>\n","      <td>6553.4</td>\n","      <td>-41</td>\n","      <td>91.4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2022-01-01</td>\n","      <td>3077</td>\n","      <td>20220101</td>\n","      <td>130718</td>\n","      <td>6553.4</td>\n","      <td>-41</td>\n","      <td>91.4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-579d8cb7-9c8a-43da-9298-d2ea0e1c7b76')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-579d8cb7-9c8a-43da-9298-d2ea0e1c7b76 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-579d8cb7-9c8a-43da-9298-d2ea0e1c7b76');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0519009f-5275-4a2a-8b39-4cb07ee105b8\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0519009f-5275-4a2a-8b39-4cb07ee105b8')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0519009f-5275-4a2a-8b39-4cb07ee105b8 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"hvcan"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# Removing 'Unnamed: 0' from hvcan df\n","\n","hvcan = hvcan.drop('Unnamed: 0', axis= 1)"],"metadata":{"id":"mU2LJBdfM3fQ","executionInfo":{"status":"ok","timestamp":1713651824190,"user_tz":360,"elapsed":144,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Eliminating redundant columns from the dataframe as they do not contribute to the problem statement.\n","\n","hvcan = hvcan.drop(['tirePressureLF',\n","                    'tirePressureRF',\n","                    'tirePressureLR',\n","                    'tirePressureRR',\n","                    'outsideAirTemp',\n","                    'outsideAirTemp',\n","                    'tmDisplayedGear',\n","                    'absWheelSpeedFL',\n","                    'absWheelSpeedFR',\n","                    'absWheelSpeedRL',\n","                    'absWheelSpeedRR',\n","                    'wheelVelLF',\n","                    'wheelVelRF',\n","                    'wheelVelLR',\n","                    'wheelVelRR'], axis=1)"],"metadata":{"id":"EnGX-MHXfsIk","executionInfo":{"status":"ok","timestamp":1713651825115,"user_tz":360,"elapsed":124,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Checking dimension of cleaned hvcan data\n","hvcan.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XP8ioDJQHCRD","executionInfo":{"status":"ok","timestamp":1713651826067,"user_tz":360,"elapsed":2,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}},"outputId":"e40ed216-3b5c-41ec-b066-6cbf13bc443c"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1358196, 22)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Checking data type, values and columns of hvcan\n","hvcan.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2PcLgkDEHG70","executionInfo":{"status":"ok","timestamp":1713651827125,"user_tz":360,"elapsed":3,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}},"outputId":"047ce00f-fd2c-4323-e67e-eb17506afb7f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1358196 entries, 0 to 1358195\n","Data columns (total 22 columns):\n"," #   Column                     Non-Null Count    Dtype  \n","---  ------                     --------------    -----  \n"," 0   partitionDate              1358196 non-null  object \n"," 1   device                     1358196 non-null  int64  \n"," 2   filedate                   1358196 non-null  int64  \n"," 3   filetimeutc                1358196 non-null  int64  \n"," 4   engineTorque               1358196 non-null  float64\n"," 5   engineCoolantTemp          1358196 non-null  int64  \n"," 6   engineAtmosphericPressure  1358196 non-null  float64\n"," 7   steeringSpeed              1358196 non-null  int64  \n"," 8   engineSpeed                1358196 non-null  int64  \n"," 9   steeringTorque             1358196 non-null  float64\n"," 10  epsLoad                    1358196 non-null  float64\n"," 11  accLsfSubseg               1358196 non-null  int64  \n"," 12  fuelUsed                   1358196 non-null  float64\n"," 13  cabinTemp                  1358196 non-null  int64  \n"," 14  compCurrent                1358196 non-null  int64  \n"," 15  latAccel                   1358196 non-null  float64\n"," 16  accelPedalPos              1358196 non-null  int64  \n"," 17  accStatus                  1358196 non-null  int64  \n"," 18  odometerMiles              1358196 non-null  float64\n"," 19  driverSeatbelt             1358196 non-null  bool   \n"," 20  accSetSpeed                1358196 non-null  float64\n"," 21  cruiseSetSpeed             1358196 non-null  float64\n","dtypes: bool(1), float64(9), int64(11), object(1)\n","memory usage: 218.9+ MB\n"]}]},{"cell_type":"code","source":["# Function to filter out groups with any NaN values and retain the first 240 rows\n","def get_first_240_rows(group):\n","    # Check if any NaN values exist in the group\n","    if group.isna().any().any() != True:\n","        return group  # Return the group if it doesn't contain any NaN values\n","\n","# Function to preprocess the DataFrame by grouping it based on 'device' and 'filetimeutc',\n","# and applying the get_first_240_rows function to each group\n","def preprocess_df(filter_data):\n","    # Group the DataFrame by 'device' and 'filetimeutc', apply the get_first_240_rows function,\n","    # and reset the index of the resulting DataFrame\n","    result = filter_data.groupby(['device', 'filetimeutc']).apply(get_first_240_rows).reset_index(drop=True)\n","    # Reset the index of the resulting DataFrame again\n","    return result.reset_index()"],"metadata":{"id":"kCsHQRs_GqRo","executionInfo":{"status":"ok","timestamp":1713651828000,"user_tz":360,"elapsed":148,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Applying preprocess_df function to hvcan dataframe\n","filter_data = preprocess_df(hvcan)"],"metadata":{"id":"SEclXm2AGqPU","executionInfo":{"status":"ok","timestamp":1713651830500,"user_tz":360,"elapsed":1541,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Function to generate lag features\n","def generate_lag(df):\n","    # Combining 'filedate' and 'filetimeutc' columns to create a datetime column\n","    df['datetime_utc'] = pd.to_datetime(df['filedate'], format='%Y%m%d') + pd.to_timedelta(df['filetimeutc'], unit='ms')\n","\n","    # Sorting the DataFrame by 'device' and 'datetime_utc' columns\n","    df = df.sort_values(by=['device', 'datetime_utc'])\n","\n","    # Grouping the DataFrame by 'device' and 'datetime_utc' columns\n","    grouped = df.groupby(['device', 'datetime_utc'])\n","\n","    # Initializing an empty list to store lag features\n","    lag_features = []\n","\n","    # Looping through a range from 1 to 7 (inclusive) to create lag features\n","    for i in range(1, 8):\n","        # Shifting the grouped data by 'i' to create lag features and add suffix to column names\n","        lag_feature = grouped[df.columns.to_list()].shift(i).add_suffix(f'_lag{i}')\n","\n","        # Appending the lag feature to the list\n","        lag_features.append(lag_feature)\n","\n","    # Concatenating the original DataFrame and lag features along columns axis\n","    return pd.concat([df] + lag_features, axis=1)"],"metadata":{"id":"xscjNbJjGqKl","executionInfo":{"status":"ok","timestamp":1713651830500,"user_tz":360,"elapsed":2,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Applying generate_lag function to filter_data\n","df_with_lag = generate_lag(filter_data)"],"metadata":{"id":"hW2FFauVGqH8","executionInfo":{"status":"ok","timestamp":1713651837373,"user_tz":360,"elapsed":6450,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Dropping rows with missing values (NaNs) from the DataFrame with lag features\n","df_with_lag.dropna(inplace=True)\n","\n","# Generat unique combinations of 'device' and 'datetime_utc' columns to represent unique trips\n","unique_combinations = df_with_lag[['device', 'datetime_utc']].drop_duplicates()\n","\n","# Spliting the unique combinations into train and test sets, ensuring all instances of a trip are in the same set\n","# This step is important for maintaining temporal integrity in time-series data\n","\n","train_combinations, test_combinations = train_test_split(unique_combinations, test_size=0.2, random_state=42)\n"],"metadata":{"id":"GxE6yfdyGqFq","executionInfo":{"status":"ok","timestamp":1713651843941,"user_tz":360,"elapsed":6581,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Checking train_combinations dataframe\n","#train_combinations.head()"],"metadata":{"id":"zqzt3TNiGqC0","executionInfo":{"status":"ok","timestamp":1713651845807,"user_tz":360,"elapsed":116,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Checking dimensions of train_combinations\n","#train_combinations.shape"],"metadata":{"id":"budTE9TCIu84","executionInfo":{"status":"ok","timestamp":1713651846324,"user_tz":360,"elapsed":1,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Checking test_combinations dataframe\n","#test_combinations.head()"],"metadata":{"id":"bXMWLur0GqAj","executionInfo":{"status":"ok","timestamp":1713651846702,"user_tz":360,"elapsed":2,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Checking dimensions of test_combinations\n","#test_combinations.shape"],"metadata":{"id":"zRn0OYtyGp-T","executionInfo":{"status":"ok","timestamp":1713651847109,"user_tz":360,"elapsed":2,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["\n","# Initializing an empty list to store train data\n","train = []\n","\n","# Iterating through each unique combination in the train_combinations DataFrame\n","for i in range(len(train_combinations)):\n","    # Filtering the DataFrame with lag features to get instances corresponding to the current combination\n","    train.append(df_with_lag[(df_with_lag['device'] == train_combinations['device'].iloc[i]) &\n","                             (df_with_lag['datetime_utc'] == train_combinations['datetime_utc'].iloc[i])])\n","\n","# Concatenating the filtered dataframes to create the training dataset\n","df_train = pd.concat(train)"],"metadata":{"id":"2Oqgcq8AGp7_","executionInfo":{"status":"ok","timestamp":1713651854798,"user_tz":360,"elapsed":7210,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Path to save the training data\n","#path_to_train = 'train2.csv'\n","\n","# Saving the training dataset DataFrame to a CSV file at the specified path\n","#df_train.to_csv(path_to_train)"],"metadata":{"id":"Jrji6sTSGp5h","executionInfo":{"status":"ok","timestamp":1713651868379,"user_tz":360,"elapsed":134,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["#from google.colab import files\n","#files.download('train2.csv')"],"metadata":{"id":"P1trSGKbj9cS","executionInfo":{"status":"ok","timestamp":1713651868807,"user_tz":360,"elapsed":3,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Checking df_train dataframe\n","#df_train.head()"],"metadata":{"id":"_ag33BehGp3P","executionInfo":{"status":"ok","timestamp":1713651869393,"user_tz":360,"elapsed":2,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# Initializing an empty list to store test data\n","test = []\n","\n","# Iteratting through each unique combination in the test_combinations DataFrame\n","for i in range(len(test_combinations)):\n","    # Filter the DataFrame with lag features to get instances corresponding to the current combination\n","    test.append(df_with_lag[(df_with_lag['device'] == test_combinations['device'].iloc[i]) &\n","                            (df_with_lag['datetime_utc'] == test_combinations['datetime_utc'].iloc[i])])\n","\n","# Concatenating the filtered dataframes to create the testing dataset\n","df_test = pd.concat(test)"],"metadata":{"id":"i-vqu5N0Gp0y","executionInfo":{"status":"ok","timestamp":1713651871289,"user_tz":360,"elapsed":1334,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# Path to save the testing data\n","#path_to_test = 'test2.csv'\n","\n","# Saving the testing dataset DataFrame to a CSV file at the specified path\n","#df_test.to_csv(path_to_test)"],"metadata":{"id":"OK4cFGh3CzgM","executionInfo":{"status":"ok","timestamp":1713651873074,"user_tz":360,"elapsed":152,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["#from google.colab import files\n","#files.download('test2.csv')"],"metadata":{"id":"Y14cTLRqkBRZ","executionInfo":{"status":"ok","timestamp":1713651873641,"user_tz":360,"elapsed":2,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Checking df_test dataframe\n","#df_test.head()"],"metadata":{"id":"LNGcTqSVCziq","executionInfo":{"status":"ok","timestamp":1713651874397,"user_tz":360,"elapsed":127,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["## Training the isolation forest"],"metadata":{"id":"qKUTSQq8JP64"}},{"cell_type":"code","source":["# Dropping specified columns from the training dataset DataFrame\n","\n","df_train = df_train.drop(['index',\n","                          'device',\n","                          'filetimeutc',\n","                          'filedate',\n","                          'datetime_utc',\n","                          'partitionDate',\n","                          'partitionDate_lag1',\n","                          'datetime_utc_lag1',\n","                          'partitionDate_lag2',\n","                          'datetime_utc_lag2',\n","                          'partitionDate_lag3',\n","                          'datetime_utc_lag3',\n","                          'partitionDate_lag4',\n","                          'datetime_utc_lag4',\n","                          'partitionDate_lag5',\n","                          'datetime_utc_lag5',\n","                          'partitionDate_lag6',\n","                          'datetime_utc_lag6',\n","                          'partitionDate_lag7',\n","                          'datetime_utc_lag7'], axis=1)\n","\n"],"metadata":{"id":"y9IHhA90Czdj","executionInfo":{"status":"ok","timestamp":1713651878128,"user_tz":360,"elapsed":1934,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Checking dataframe df_train\n","#df_train.head()"],"metadata":{"id":"FnYFymCBKkVM","executionInfo":{"status":"ok","timestamp":1713651968461,"user_tz":360,"elapsed":126,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# Initialize and fit an IsolationForest model to the training data\n","clf = IsolationForest(random_state=0).fit(df_train)"],"metadata":{"id":"CKoROhKbCzbH","executionInfo":{"status":"ok","timestamp":1713651975193,"user_tz":360,"elapsed":3161,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Predicting outliers in the training dataset using the IsolationForest model\n","df_train['pred'] = clf.predict(df_train)"],"metadata":{"id":"tmSSmHkYJqEj","executionInfo":{"status":"ok","timestamp":1713652052916,"user_tz":360,"elapsed":77725,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["# Defining Scoring Model\n"],"metadata":{"id":"z8PJ6zBnUeCK"}},{"cell_type":"code","source":["def get_trip_data(df, device, filetimeutc):\n","\n","    # Filtering DataFrame to get samples for a specific device and filetimeutc\n","    return df[(df['device'] == device) & (df['filetimeutc'] == filetimeutc)]"],"metadata":{"id":"-eD10wxWTC49","executionInfo":{"status":"ok","timestamp":1713652052917,"user_tz":360,"elapsed":17,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["def calculate_trip_duration(sample_count):\n","\n","    # Calculating the duration of a trip in minutes based on the number of samples\n","    return sample_count / 300  # Each row represents 5 seconds"],"metadata":{"id":"sEW711cOTEUq","executionInfo":{"status":"ok","timestamp":1713652052917,"user_tz":360,"elapsed":16,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["def calculate_score_change(df_sample):\n","\n","    \"\"\"Calculate the change in score based on predictions and scores in the sample.\"\"\"\n","\n","    # Initialize variables\n","    max_neg = 0\n","    curr_score = 0\n","    window_len = 30  # Length of the sliding window in seconds\n","    rows_per_batch = window_len / 5  # Number of rows per batch (each row represents 5 seconds)\n","\n","    # Iterate through each prediction and score in the sample\n","    for pred, pred_score in zip(df_sample['pred'], df_sample['predscore']):\n","\n","        # Check if there are rows left in the current batch\n","        if rows_per_batch > 0:\n","            # Update 'max_neg' if the prediction is negative (outlier)\n","            max_neg = max(max_neg, abs(pred_score) - 0.5) if pred == -1 else max_neg\n","            rows_per_batch -= 1  # Decrement rows_per_batch\n","\n","        # If the batch window is exhausted\n","        elif rows_per_batch == 0:\n","            # Update the score based on 'max_neg'\n","            curr_score -= 5 * (max_neg * 10) ** 2 if max_neg > 0 else 0\n","\n","            # Reset 'max_neg' if the current prediction is negative (outlier)\n","            max_neg = abs(pred_score) - 0.5 if pred == -1 else 0\n","\n","            # Reset rows_per_batch and decrement it for the next batch\n","            rows_per_batch = window_len / 5 - 1\n","\n","    return curr_score"],"metadata":{"id":"E9w6y4zKTERr","executionInfo":{"status":"ok","timestamp":1713652052917,"user_tz":360,"elapsed":16,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["def score_trip(df, keys, d_curr_ratings, trip_list=[]):\n","\n","    \"\"\"Score each trip based on predictions and update the rating dictionary.\"\"\"\n","\n","    # Iterate over each key in the keys list\n","    for key in keys:\n","        # Filter DataFrame to get samples for the current key\n","        df_sample = get_trip_data(df, key[0], key[1])\n","\n","        # Calculate trip duration\n","        duration_of_trip = calculate_trip_duration(len(df_sample))\n","\n","        # Calculate duration of positive predictions\n","        duration_pos_len = calculate_trip_duration(len(df_sample[df_sample['pred'] == 1]))\n","\n","        # Calculate duration of negative predictions\n","        duration_neg_len = duration_of_trip - duration_pos_len\n","\n","        # Calculate score change based on predictions and scores\n","        score_change = calculate_score_change(df_sample)\n","\n","        # Update the current score for the device\n","        curr_score = d_curr_ratings[key[0]] + duration_pos_len + score_change\n","        d_curr_ratings[key[0]] = curr_score\n","\n","        # Append device, filetimeutc, and score to trip_list\n","        trip_list.append((key[0], key[1], curr_score))\n","\n","    return trip_list"],"metadata":{"id":"fzpi67T0TEPj","executionInfo":{"status":"ok","timestamp":1713652052917,"user_tz":360,"elapsed":16,"user":{"displayName":"Sushil Deore","userId":"00457694906619664958"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# Reading the CSV file into a DataFrame\n","df_train = pd.read_csv('/content/drive/MyDrive/Honda Capstone Project- MOVE/train2.csv')\n","\n","# Displaying the first few rows of the DataFrame\n","df_train.head()"],"metadata":{"id":"Wr2k9NzcMIyY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dropping specified columns from the DataFrame 'df_train' and assign the result to 'df_req'\n","\n","df_req = df_train.drop(['index',\n","                        'device',\n","                        'filetimeutc',\n","                        'filedate',\n","                        'datetime_utc',\n","                        'partitionDate',\n","                        'partitionDate_lag1',\n","                        'datetime_utc_lag1',\n","                        'partitionDate_lag2',\n","                        'datetime_utc_lag2',\n","                        'partitionDate_lag3',\n","                        'datetime_utc_lag3',\n","                        'partitionDate_lag4',\n","                        'datetime_utc_lag4',\n","                        'partitionDate_lag5',\n","                        'datetime_utc_lag5',\n","                        'partitionDate_lag6',\n","                        'datetime_utc_lag6',\n","                        'partitionDate_lag7',\n","                        'datetime_utc_lag7'], axis=1)\n"],"metadata":{"id":"tTDO3DBrMa1z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Removing 'Unnamed: 0' from df_req\n","\n","df_req.drop('Unnamed: 0', inplace = True, axis = 1)"],"metadata":{"id":"pVFHyfBAMazg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predicting outliers in the DataFrame 'df_req' using the IsolationForest model 'clf'\n","# and assign the predictions to a new column 'pred' in 'df_train'\n","\n","df_train['pred'] = clf.predict(df_req)"],"metadata":{"id":"YwDBvfPRMaw4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculating anomaly scores for each sample in the DataFrame 'df_req' using the IsolationForest model 'clf'\n","# and assign the scores to a new column 'predscore' in 'df_train'\n","\n","df_train['predscore'] = clf.score_samples(df_req)"],"metadata":{"id":"Ed-7X_eXMMtq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Getting the unique keys (combinations of 'device' and 'filetimeutc') for the trip from the DataFrame 'df_train' along with their counts\n","\n","df_keys = df_train[['device','filetimeutc']].value_counts()"],"metadata":{"id":"rISeDYPVMr4r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Resetting the index of the DataFrame 'df_keys'\n","df_keys = df_keys.reset_index()"],"metadata":{"id":"jseF8wy4Mzex"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a list of tuples containing unique combinations of 'device' and 'filetimeutc' from the DataFrame 'df_keys'\n","keys = list(zip(df_keys['device'], df_keys['filetimeutc']))"],"metadata":{"id":"lurTQ08JMzcp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Importing defaultdict from collections module\n","from collections import defaultdict\n","\n","# Initialize an empty list to store trip details\n","tp_list = []\n","\n","# Initialize a defaultdict to store current ratings for drivers, defaulting to 1500\n","driver_curr_ratings = defaultdict(lambda: 1500)\n","\n","# Calculate scores for each trip based on predictions and update driver ratings\n","tp_list = score_trip(df_train, keys, driver_curr_ratings, tp_list)\n"],"metadata":{"id":"B2KUqkN4MzaK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZOy73J9CnvwR"},"execution_count":null,"outputs":[]}]}